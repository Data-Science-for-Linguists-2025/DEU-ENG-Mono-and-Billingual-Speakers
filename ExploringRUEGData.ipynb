{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a745238f",
   "metadata": {},
   "source": [
    "# Exploring the RUEG Corpus\n",
    "Goals\n",
    "\n",
    "## Table of Contents\n",
    "1. [Unigram Exploration]()\n",
    "\n",
    "    A. [Loading in the Data]()\n",
    "2. [Taking in Some Basic Stats]()\n",
    "3. [Exloring with the POS]()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7a501e",
   "metadata": {},
   "source": [
    "## Unigram Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafb2ac4",
   "metadata": {},
   "source": [
    "### Loading in the Data\n",
    "Load in the pickle files created in [this](https://github.com/Data-Science-for-Linguists-2025/DEU-ENG-Mono-and-Billingual-Speakers/blob/main/LoadingRUEGData.ipynb) jupyter notebook, and poking around a bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f29328c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty printing has been turned ON\n"
     ]
    }
   ],
   "source": [
    "%pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8b9e98fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90bc4349",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('debi_pos.pkl', 'rb') as file:\n",
    "    DE_bi_pos = pickle.load(file)\n",
    "with open ('demono_pos.pkl', 'rb') as file:\n",
    "    DE_mono_pos = pickle.load(file)\n",
    "with open ('enbi_pos.pkl', 'rb') as file:\n",
    "    EN_bi_pos = pickle.load(file)\n",
    "with open ('enmono_pos.pkl', 'rb') as file:\n",
    "    EN_mono_pos = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "64669b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('debi_text.pkl', 'rb') as file:\n",
    "    DE_bi_tokens = pickle.load(file)\n",
    "with open ('demono_text.pkl', 'rb') as file:\n",
    "    DE_mono_tokens = pickle.load(file)\n",
    "with open ('enbi_text.pkl', 'rb') as file:\n",
    "    EN_bi_tokens = pickle.load(file)\n",
    "with open ('enmono_text.pkl', 'rb') as file:\n",
    "    EN_mono_tokens = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0302e4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4773\n",
      "1761\n",
      "4385\n",
      "621\n",
      "4773\n",
      "1761\n",
      "4385\n",
      "621\n"
     ]
    }
   ],
   "source": [
    "print(len(DE_bi_pos))\n",
    "print(len(DE_mono_pos))\n",
    "print(len(EN_bi_pos))\n",
    "print(len(EN_mono_pos))\n",
    "\n",
    "print(len(DE_bi_tokens))\n",
    "print(len(DE_mono_tokens))\n",
    "print(len(EN_bi_tokens))\n",
    "print(len(EN_mono_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0348e849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('und', 'CCONJ'),\n",
       " ('die', 'PRON'),\n",
       " ('haben', 'AUX'),\n",
       " ('die', 'DET'),\n",
       " ('Polizei', 'NOUN'),\n",
       " ('äh', 'INTJ'),\n",
       " ('angerufen', 'VERB'),\n",
       " ('DEbi24FT', 'PROPN'),\n",
       " ('und', 'CCONJ'),\n",
       " ('ist', 'AUX')]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DE_bi_pos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57c800a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['und',\n",
       " 'die',\n",
       " 'haben',\n",
       " 'die',\n",
       " 'Polizei',\n",
       " 'äh',\n",
       " 'angerufen',\n",
       " 'DEbi24FT',\n",
       " 'und',\n",
       " 'ist']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DE_bi_tokens[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08805183",
   "metadata": {},
   "source": [
    "So, unfortunately, after investigating some POS tags, there are some non-UPOS tags included in the German sets. This is likely from some kind of incorrect parsing from the stanza parsing, or incorrectly marked in the actual text (it was automatic POS tagging, not by hand with exMaralda)\n",
    "\n",
    "For out purposes, I decided to just exlude these instances from the data here. They will not be helpful and there really isn't another solution here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a7572939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NOUN', 702), ('DET', 618), ('VERB', 558), ('ADV', 550), ('PRON', 448), ('AUX', 354), ('CCONJ', 341), ('ADP', 292), ('ADJ', 291), ('PUNCT', 251), ('INTJ', 175), ('PROPN', 51), ('SYM', 29), ('PART', 23), ('NUM', 22), ('SCONJ', 7)]\n"
     ]
    }
   ],
   "source": [
    "DE_bi_pos = [x for x in DE_bi_pos if x[1] not in ['NE', '_', '$.', 'X']]\n",
    "debi_postags = [x[1] for x in DE_bi_pos]\n",
    "debitagfd = nltk.FreqDist(debi_postags)\n",
    "print(debitagfd.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "75302e52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NOUN', 251), ('DET', 210), ('ADV', 207), ('VERB', 189), ('PRON', 176), ('AUX', 127), ('CCONJ', 119), ('ADP', 115), ('ADJ', 113), ('PUNCT', 100), ('INTJ', 92), ('SYM', 20), ('PROPN', 17), ('NUM', 8), ('PART', 7), ('SCONJ', 3)]\n"
     ]
    }
   ],
   "source": [
    "DE_mono_pos = [x for x in DE_mono_pos if x[1] not in ['PPER', 'VAFIN', 'KON', 'PIAT', 'NN']]\n",
    "demono_postags = [x[1] for x in DE_mono_pos]\n",
    "demonotagfd = nltk.FreqDist(demono_postags)\n",
    "print(demonotagfd.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c86e771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('NOUN', 685), ('VERB', 675), ('DET', 673), ('ADP', 420), ('PROPN', 330), ('CCONJ', 268), ('AUX', 251), ('ADV', 234), ('ADJ', 212), ('PUNCT', 200), ('PART', 119), ('SCONJ', 112), ('PRON', 91), ('INTJ', 75), ('NUM', 36)]\n"
     ]
    }
   ],
   "source": [
    "EN_bi_pos = [x for x in EN_bi_pos if x[1] != '_']\n",
    "enbi_postags = [x[1] for x in EN_bi_pos]\n",
    "enbitagfd = nltk.FreqDist(enbi_postags)\n",
    "print(enbitagfd.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "267e0538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('DET', 102), ('VERB', 99), ('NOUN', 92), ('ADP', 61), ('CCONJ', 44), ('PROPN', 43), ('ADJ', 34), ('AUX', 33), ('ADV', 31), ('PUNCT', 21), ('PART', 19), ('PRON', 17), ('SCONJ', 17), ('INTJ', 7), ('NUM', 1)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enmono_postags = [x[1] for x in EN_mono_pos]\n",
    "enmonotagfd = nltk.FreqDist(enmono_postags)\n",
    "print(enmonotagfd.most_common())\n",
    "len(set(enmono_postags))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af272621",
   "metadata": {},
   "source": [
    "These are a little harder to compare, because we know that the sizes of the texts are pretty different. Another thing to consider is similar to the issue with TTR (it is hard to compare Type to Token Ratio when text sizes are vastly different becasue stop words will have a larger proportion in longer text). If these text sizes are so different (mostly considering the English Monolingual) it may be harder to compare. I will do the best I can, but this is crucial to keep in mind whenever comparing the four partitions.\n",
    "\n",
    "That being said, It's still fair to say that nouns, determinersa and verbs are in the top among all sets. What is interesting is the greater use of adverbs in German speakers comapred to more use of adpositions in English. At this point, it is hard to see the similarites of Bilingual speakers in comaprison to monolingual speakers, and minute differences may be difficult to see with the human eye and will require some kind of machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c63a3aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('und', 'CCONJ'), 221), (('.', 'PUNCT'), 175), (('die', 'DET'), 155), (('der', 'DET'), 120), (('Polizei', 'NOUN'), 118), (('Auto', 'NOUN'), 94), (('dann', 'ADV'), 81), (('ist', 'AUX'), 75), (('äh', 'INTJ'), 60), (('das', 'DET'), 60), (('es', 'PRON'), 59), ((',', 'PUNCT'), 54), (('hat', 'AUX'), 54), (('ich', 'PRON'), 52), (('dem', 'DET'), 49), (('ja', 'INTJ'), 47), (('haben', 'AUX'), 44), (('den', 'DET'), 43), (('war', 'AUX'), 41), (('ein', 'DET'), 38)]\n"
     ]
    }
   ],
   "source": [
    "debiposfd = nltk.FreqDist(DE_bi_pos)\n",
    "print(debiposfd.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "37835eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('und', 'CCONJ'), 76), (('.', 'PUNCT'), 66), (('die', 'DET'), 37), (('der', 'DET'), 35), (('ist', 'AUX'), 31), (('dann', 'ADV'), 29), (('dem', 'DET'), 29), (('den', 'DET'), 27), (('ja', 'INTJ'), 26), (('Auto', 'NOUN'), 25), (('ich', 'PRON'), 25), ((',', 'PUNCT'), 24), (('war', 'AUX'), 23), (('das', 'PRON'), 23), (('mit', 'ADP'), 22), (('Polizei', 'NOUN'), 19), (('nicht', 'INTJ'), 19), (('es', 'PRON'), 18), (('auf', 'ADP'), 18), (('das', 'DET'), 17)]\n"
     ]
    }
   ],
   "source": [
    "demonoposfd = nltk.FreqDist(DE_mono_pos)\n",
    "print(demonoposfd.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "fa0a984e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('the', 'DET'), 428), (('and', 'CCONJ'), 220), (('.', 'PUNCT'), 158), (('car', 'NOUN'), 144), (('to', 'PART'), 89), (('was', 'AUX'), 87), (('of', 'ADP'), 83), (('it', 'PROPN'), 78), (('called', 'VERB'), 72), (('they', 'PROPN'), 51), (('in', 'ADP'), 50), (('then', 'ADV'), 50), (('him', 'PROPN'), 50), (('I', 'PROPN'), 45), (('911', 'NOUN'), 45), (('behind', 'ADP'), 45), (('police', 'NOUN'), 44), (('hit', 'VERB'), 40), (('to', 'ADP'), 40), (('a', 'DET'), 39)]\n"
     ]
    }
   ],
   "source": [
    "enbiposfd = nltk.FreqDist(EN_bi_pos)\n",
    "print(enbiposfd.most_common(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6689b43f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(('the', 'DET'), 62), (('and', 'CCONJ'), 39), (('car', 'NOUN'), 35), (('.', 'PUNCT'), 19), (('it', 'PROPN'), 17), (('was', 'AUX'), 16), (('to', 'PART'), 13), (('other', 'ADJ'), 11), (('one', 'PRON'), 9), (('of', 'ADP'), 9), (('rear-ended', 'VERB'), 9), (('him', 'PROPN'), 9), (('hit', 'VERB'), 9), (('into', 'ADP'), 8), (('then', 'ADV'), 8), (('they', 'PROPN'), 8), (('behind', 'ADP'), 8), (('stopped', 'VERB'), 7), (('that', 'DET'), 7), (('in', 'ADP'), 7)]\n"
     ]
    }
   ],
   "source": [
    "enmonoposfd = nltk.probability.FreqDist(EN_mono_pos)\n",
    "print(enmonoposfd.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83235af7",
   "metadata": {},
   "source": [
    "#### What are we seeing here\n",
    "Let me translate what exactly is happening here with the langauges. First, it's important to recognize that some of these recording are coming from a situation in which the participants were asked to describe a video they saw about a car crash as if they had witnessed the car crash which is why words like 'Polizei' (English: Police) and 'Auto' and 'car' are common.\n",
    "\n",
    "Secondly, when looking at the distribution of stop words, it is a little different. For one, the most common word in both German texts is 'und' (English: and) while the most common word in English is 'the'. This is likely because German has several different words for 'the' (der, die, das, den, dem, des) so the distribution is spread across these several words. The bilingual sets are pretty comparable becasue they have similar sizes, and when looking at 'und' and 'and', they have pretty similar usuage.\n",
    "\n",
    "Additionally, some of these texts are transcriptions of *spoken* audio, so the punctuation is a little tricky to analyze and not going to be of a whole lot of importance to this anyway."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad645cb",
   "metadata": {},
   "source": [
    "### Combing the Bilingual v Monolingual\n",
    "Let's combine the bilingual and monolingual data and just look at pos to see if that will show any greater differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f490b722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9093\n",
      "2375\n"
     ]
    }
   ],
   "source": [
    "bilingual_uni_pos = EN_bi_pos + DE_bi_pos\n",
    "print(len(bilingual_uni_pos))\n",
    "\n",
    "monolingual_uni_pos = EN_mono_pos + DE_mono_pos\n",
    "print(len(monolingual_uni_pos))\n",
    "\n",
    "## big size discrepency to keep in mind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6b205d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NOUN', 1387),\n",
       " ('DET', 1291),\n",
       " ('VERB', 1233),\n",
       " ('ADV', 784),\n",
       " ('ADP', 712),\n",
       " ('CCONJ', 609),\n",
       " ('AUX', 605),\n",
       " ('PRON', 539),\n",
       " ('ADJ', 503),\n",
       " ('PUNCT', 451),\n",
       " ('PROPN', 381),\n",
       " ('INTJ', 250),\n",
       " ('PART', 142),\n",
       " ('SCONJ', 119),\n",
       " ('NUM', 58),\n",
       " ('SYM', 29)]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biuni_postags = [x[1] for x in bilingual_uni_pos]\n",
    "biuni_postagsfd = nltk.FreqDist(biuni_postags)\n",
    "biuni_postagsfd.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e03ad6ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NOUN', 343),\n",
       " ('DET', 312),\n",
       " ('VERB', 288),\n",
       " ('ADV', 238),\n",
       " ('PRON', 193),\n",
       " ('ADP', 176),\n",
       " ('CCONJ', 163),\n",
       " ('AUX', 160),\n",
       " ('ADJ', 147),\n",
       " ('PUNCT', 121),\n",
       " ('INTJ', 99),\n",
       " ('PROPN', 60),\n",
       " ('PART', 26),\n",
       " ('SCONJ', 20),\n",
       " ('SYM', 20),\n",
       " ('NUM', 9)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monouni_postags = [x[1] for x in monolingual_uni_pos]\n",
    "monouni_postagsfd = nltk.FreqDist(monouni_postags)\n",
    "monouni_postagsfd.most_common(20)\n",
    "\n",
    "## with just the POS, we can compare how the first four groups are similar,\n",
    "## however pronoun usuage is clearly different and greater in the monolingual\n",
    "## speakers, but everything else is nearly identical- very cool!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99f7a00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
